{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question 12: '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Question 1: \n",
    "    You would have to use a method that is less influenced by the number of features.\n",
    "    You could use a Gradient Descent, like Stochastic Gradient Descent or Mini-batch gradient descent\n",
    "    \n",
    "Question 2: \n",
    "    The difference in scale would cause the cost function look like a long shallow bowl. This would cause\n",
    "    Gradient Descent algorithms to converge slowly, as they would need more \"jumps.\" A simple solution is \n",
    "    to scale features to fit more uniformly.Using an algorithm like SVD or Natural Equation would not benifit \n",
    "    from scaling. Regularized models could also suffer without scaling because the larger values would cause\n",
    "    lower ones to be ignored\n",
    "\n",
    "Question 3:\n",
    "    No, because the model would would appear convex, not concave.\n",
    "    \n",
    "Question 4:\n",
    "    For methods like Linear Regression and Logistic Regression using gradient descent, if done right the models \n",
    "    can be made to be very over time. This requires the a small learning rate. Another Point is that even if you\n",
    "    let a Stochastic GD or Minibatch GD run for a long time, they would still produce models that are a little different\n",
    "\n",
    "Question 5:\n",
    "    This could be the result of overfitting or diverging. If you notice the training error is not going up, that\n",
    "    means that the model is overfitting. If the training error is also going up, then that is a sign that the learning\n",
    "    rate is too high, causing the diversion\n",
    "  \n",
    "Question 6:\n",
    "    No, the algorithm makes jumps randomly, so not all iterations make positive progress.\n",
    "\n",
    "Question 7:\n",
    "    Stochastic Gradient Descent will get close to the optimal solution fastest. Batch Gradient Descent would actually be\n",
    "    able to converge. One way to improve the convergence of Stochastic Gradient Descent is to slowly lower the training rate\n",
    "    as it gets closer to the optimum. That would prevent it from iterating around in the area without making progres.\n",
    "    \n",
    "Question 8:\n",
    "    Overfitting can cause gaps between training error and validation error, esspecially if training error does not increase.\n",
    "    You could decrease the degree of the model, regularize the model, or increase the training size.\n",
    "\n",
    "Question 9:\n",
    "    If both are high then the system has a high variance. This is typical of underfitting. the hyperparameter a should be reduced\n",
    "    because the model is too regular. \n",
    "    \n",
    "Question 10:\n",
    "    As long as regularization is used properly, it tends to improve models. Over regularized models underfit, and unregularized models\n",
    "    can easily overfit.\n",
    "    This descision depends on the scenario; simply put, if the model has many unneccessary features lasso will automatically render them out\n",
    "    If you think that all of the features should be important for your dataset, you should use Ridge Regression.\n",
    "    Yes, Elastic Net is typically better than Lasso. The downside is that it is more complicated \n",
    "\n",
    "Question 11:\n",
    "    Two logistic regressors would be best, since there are four possibilities. out-day, out-night, in-day, in-night.\n",
    "    \n",
    "\"\"\"\n",
    "\"Question 12: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = iris[\"data\"][:, (2, 3)]  #length and width of petals\n",
    "y = iris[\"target\"]\n",
    "biasX = np.c_[np.ones([len(X), 1]), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalLen = len(biasX)\n",
    "totalLen # how much data are we working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSetLen = int(0.2 * totalLen)\n",
    "testSetLen # we should set aside 20% of the data. How much is that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationSetLen = int(0.2 * totalLen)\n",
    "validationSetLen # we should set aside 20% of the data. How much is that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSetLen = totalLen - testSetLen - validationSetLen\n",
    "trainingSetLen # 80% left to train on. How much is that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized = np.random.permutation(totalLen) #randomize indecies in the hopes of even sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTraining = biasX[randomized[:trainingSetLen]] # grab 0-90 random items for training\n",
    "yTraining = y[randomized[:trainingSetLen]] # grab 0-90 random items for training\n",
    "XValidation = biasX[randomized[trainingSetLen:-validationSetLen]]# grab 30 random items for validation\n",
    "yValidation = y[randomized[trainingSetLen:-validationSetLen]]# grab 30 random items for validation\n",
    "XTest = biasX[randomized[-testSetLen:]]# grab 30 random items for testing\n",
    "yTest = y[randomized[-testSetLen:]]# grab 30 random itemsfor testing\n",
    "# Note that this is a random mapping method. the randomness is decided once and then related to the the iterable arrays\n",
    "# If you would choose random elements for each, there would be repeated data and unused data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotCoverter(vectorIn):\n",
    "    numberOfClasses = vectorIn.max() + 1 \n",
    "    vectorLength = len(vectorIn)\n",
    "    oneHotMatrixOut = np.zeros((vectorLength, numberOfClasses))\n",
    "    oneHotMatrixOut[np.arange(vectorLength), vectorIn] = 1\n",
    "    return oneHotMatrixOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 1, 2, 1, 2, 0, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 1, 0, 0,\n",
       "       2, 0, 1, 0, 2, 1, 0, 0, 2, 0, 0, 1, 0, 1, 1, 2, 1, 0, 2, 0, 0, 2,\n",
       "       2, 1, 1, 1, 2, 0, 2, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 1, 0, 0, 2, 2,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotCoverter(yTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotTest = oneHotCoverter(yTest)\n",
    "oneHotYValidation = oneHotCoverter(yValidation)\n",
    "oneHotYTraining = oneHotCoverter(yTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    return exps / exp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfInputs = XTraining.shape[1]\n",
    "numOfOutputs = len(np.unique(yTraining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.183534235145468\n",
      "3 0.9229714732760785\n",
      "4 0.9441280062783698 Error increased, Stopping Early\n"
     ]
    }
   ],
   "source": [
    "# Formulas come from chapter, and I looked to the solutions to get implementation ideas\n",
    "eta = 0.1     #Fairly High, since we will be employing stopping early\n",
    "numIterations = 5001\n",
    "m = len(XTraining)\n",
    "epsilon = 1e-7\n",
    "alpha = 0.1  # regularization hyperparamer\n",
    "bestLoss = np.infty # used for early stopping\n",
    "\n",
    "\n",
    "Theta = np.random.randn(numOfInputs, numOfOutputs)\n",
    "\n",
    "for iteration in range(numIterations):\n",
    "    logits = XTraining.dot(Theta)\n",
    "    Yprob = softmax(logits)\n",
    "    entropy = -np.mean(np.sum(oneHotYTraining * np.log(Yprob + epsilon), axis=1))\n",
    "    l2Loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
    "    loss = entropy + alpha * l2Loss\n",
    "    error = Yprob - oneHotYTraining\n",
    "    gradients = 1/m * XTraining.T.dot(error) + np.r_[np.zeros([1, numOfOutputs]), alpha * Theta[1:]]\n",
    "    Theta = Theta - eta * gradients\n",
    "    logits = XValidation.dot(Theta)\n",
    "    Yprob = softmax(logits)\n",
    "    entropy = -np.mean(np.sum(oneHotYValidation * np.log(Yprob + epsilon), axis=1))\n",
    "    l2Loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
    "    loss = entropy + alpha * l2Loss\n",
    "    if iteration % 500 == 0:\n",
    "        print(iteration, loss)\n",
    "    if loss < bestLoss:\n",
    "        bestLoss = loss\n",
    "    else:\n",
    "        print(iteration - 1, bestLoss)\n",
    "        print(iteration, loss, \"Error increased, Stopping Early\")\n",
    "        break\n",
    "\n",
    "\n",
    "    ##Model Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.61567478, -0.1062535 , -0.21366086],\n",
       "       [-0.29183995,  0.30111364,  0.01786701],\n",
       "       [ 0.61441884,  0.20956269,  1.22075298]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta #Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5666666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Numpy to determine the accuracy of the model\n",
    "logits = XValidation.dot(Theta)\n",
    "Yprob = softmax(logits)\n",
    "predictions = np.argmax(Yprob, axis=1)\n",
    "\n",
    "score = np.mean(predictions == yValidation)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After multiple runs, with different choices for validation sets and such\n",
    "# Models created were able to obtain anywhere from 20 - 100 percent accuracy.\n",
    "# This is caused by the early stopping. If the model starts by moving away from\n",
    "# The optimal, early stopping will need to be rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = XTest.dot(Theta)\n",
    "Yprob = softmax(logits)\n",
    "predictions = np.argmax(Yprob, axis=1)\n",
    "\n",
    "score = np.mean(predictions == yTest)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results on the test set are similar, sometimes reaching 100 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
